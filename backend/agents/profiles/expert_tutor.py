"""
Expert Tutor Engine â€” Research-Backed Adaptive Teaching System
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
An elite tutor that automatically detects when LLM knowledge is insufficient,
triggers deep internet research (web + academic + social), and delivers
expert-level coaching using 5 proven teaching techniques.

Teaching Techniques:
  ðŸ§ª Feynman       â€” Explain complex ideas simply with analogies
  ðŸ—ï¸ Scaffolding   â€” Build knowledge layer by layer
  ðŸ¦‰ Socratic      â€” Guide via probing questions
  ðŸŒ‰ Analogy Bridge â€” Connect unknowns to student's existing knowledge
  ðŸ§© Chunking      â€” Break massive topics into micro-lessons

Key Innovation:
  If the LLM response shows uncertainty (hedging language, vagueness),
  the tutor AUTOMATICALLY triggers deep web + social research and weaves
  real-world expert knowledge into the coaching session.
"""

import json
import logging
import re
import time
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any, Callable, Dict, List, Optional, Tuple

logger = logging.getLogger(__name__)


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Enums & Data Models
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class TeachingTechnique(Enum):
    FEYNMAN = "feynman"
    SCAFFOLDING = "scaffolding"
    SOCRATIC = "socratic"
    ANALOGY_BRIDGE = "analogy_bridge"
    CHUNKING = "chunking"
    ANTI_PATTERN = "anti_pattern"          # ðŸš« "Don't Do This" lessons from mistakes
    VISUAL_FLOWCHART = "visual_flowchart"  # ðŸ“Š Teach with flowcharts & diagrams
    GAME_CHALLENGE = "game_challenge"      # ðŸŽ® Gamified quiz/challenge mode


class StudentLevel(Enum):
    BEGINNER = "beginner"
    INTERMEDIATE = "intermediate"
    ADVANCED = "advanced"
    EXPERT = "expert"


@dataclass
class DiagnosticResult:
    """Result of diagnosing the student's current level."""
    level: StudentLevel = StudentLevel.BEGINNER
    confidence: float = 0.0
    knowledge_gaps: List[str] = field(default_factory=list)
    strengths: List[str] = field(default_factory=list)


@dataclass
class ResearchIntel:
    """Teaching material compiled from deep research."""
    topic: str = ""
    eli5_explanations: List[str] = field(default_factory=list)
    expert_insights: List[str] = field(default_factory=list)
    real_world_examples: List[str] = field(default_factory=list)
    practice_problems: List[str] = field(default_factory=list)
    academic_findings: List[str] = field(default_factory=list)
    social_wisdom: List[str] = field(default_factory=list)
    sources: List[Dict[str, str]] = field(default_factory=list)


@dataclass
class TutoringSession:
    """State for an active tutoring session."""
    session_id: str = ""
    topic: str = ""
    student_level: StudentLevel = StudentLevel.BEGINNER
    current_technique: TeachingTechnique = TeachingTechnique.SCAFFOLDING
    research_intel: Optional[ResearchIntel] = None
    research_triggered: bool = False
    history: List[Dict[str, str]] = field(default_factory=list)
    diagnostic: Optional[DiagnosticResult] = None
    lesson_plan: List[str] = field(default_factory=list)
    current_lesson_step: int = 0
    confidence_scores: List[float] = field(default_factory=list)
    started_at: float = field(default_factory=time.time)

    # â”€â”€ Mistake-Based Teaching â”€â”€
    anti_pattern_lessons: List[Any] = field(default_factory=list)
    mistake_curriculum: Any = None
    anti_patterns_shown: int = 0

    # â”€â”€ Gamification â”€â”€
    player_state: Any = None          # GamifiedTutorEngine.PlayerState
    active_challenge: Any = None      # Active Challenge object
    game_engine: Any = None           # GamifiedTutorEngine reference


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Confidence / Uncertainty Detection
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# Patterns that indicate the LLM is uncertain or lacks knowledge
_UNCERTAINTY_PATTERNS = [
    r"\bi(?:'m| am) not (?:entirely |completely |100%? )?sure\b",
    r"\bi(?:'m| am) not (?:entirely )?certain\b",
    r"\bi think\b(?! you)",
    r"\bit(?:'s| is) possible that\b",
    r"\bi believe\b",
    r"\bperhaps\b",
    r"\bprobably\b",
    r"\bmight be\b",
    r"\bcould be\b",
    r"\bI don'?t have (?:enough |sufficient )?(?:information|knowledge|data)\b",
    r"\bI(?:'m| am) not (?:an )?expert\b",
    r"\bmy (?:knowledge|training|data) (?:is |was )?(?:limited|cut ?off)\b",
    r"\bI (?:can'?t|cannot) (?:verify|confirm|guarantee)\b",
    r"\bgenerally speaking\b",
    r"\bin general\b",
    r"\bas far as I know\b",
    r"\bto the best of my knowledge\b",
    r"\byou (?:should|might want to) (?:consult|check|verify|look up)\b",
]

_VAGUE_PATTERNS = [
    r"\bsome (?:people|experts|sources) (?:say|think|believe)\b",
    r"\bit depends\b",
    r"\bthere are (?:many|various|different) (?:ways|approaches|methods)\b",
    r"\bthis is a complex topic\b",
    r"\bthe (?:answer|topic) is (?:nuanced|complex|multifaceted)\b",
]

_compiled_uncertainty = [re.compile(p, re.IGNORECASE) for p in _UNCERTAINTY_PATTERNS]
_compiled_vague = [re.compile(p, re.IGNORECASE) for p in _VAGUE_PATTERNS]


def detect_uncertainty(response: str) -> Tuple[float, List[str]]:
    """
    Analyze an LLM response for uncertainty signals.
    
    Returns:
        (uncertainty_score, matched_signals) where score is 0.0-1.0.
        Score > 0.4 means research should be triggered.
    """
    matched = []
    
    # Check uncertainty patterns (high weight)
    for pattern in _compiled_uncertainty:
        if pattern.search(response):
            matched.append(f"uncertainty: {pattern.pattern[:40]}")
    
    # Check vague patterns (medium weight)
    for pattern in _compiled_vague:
        if pattern.search(response):
            matched.append(f"vague: {pattern.pattern[:40]}")
    
    # Check response length (very short responses often indicate lack of knowledge)
    word_count = len(response.split())
    if word_count < 30:
        matched.append("very_short_response")
    
    # Calculate score
    uncertainty_weight = sum(1 for m in matched if m.startswith("uncertainty"))
    vague_weight = sum(0.5 for m in matched if m.startswith("vague"))
    short_weight = 0.3 if "very_short_response" in matched else 0.0
    
    raw_score = uncertainty_weight * 0.15 + vague_weight * 0.15 + short_weight
    score = min(1.0, raw_score)
    
    return score, matched


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Teaching Technique Prompts
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_TECHNIQUE_PROMPTS = {
    TeachingTechnique.FEYNMAN: """\
ðŸ§ª FEYNMAN TECHNIQUE MODE:
You are teaching using the Feynman Technique â€” the gold standard for deep understanding.
Rules:
1. Explain the concept as if teaching a smart 12-year-old
2. Use REAL-WORLD ANALOGIES for every abstract concept
3. When you hit something complex, break it into simpler sub-concepts
4. Use "Imagine you're..." or "Think of it like..." frequently
5. After explaining, ask: "Can you explain this back to me in your own words?"
6. If the student's explanation has gaps, gently point them out
7. NO jargon without immediately defining it with an analogy""",

    TeachingTechnique.SCAFFOLDING: """\
ðŸ—ï¸ SCAFFOLDING MODE:
You are building knowledge layer by layer, like constructing a building.
Rules:
1. Start with the FOUNDATION â€” what does the student already know?
2. Each new concept builds on the PREVIOUS one â€” never skip a level
3. Provide a "knowledge checkpoint" after every 2-3 concepts
4. If the student fails a checkpoint, go back ONE layer and reinforce
5. Use this pattern: Foundation â†’ Core Concept â†’ Application â†’ Integration
6. Give specific examples at each layer
7. End each message with: "Before we go deeper, let me check: [checkpoint question]" """,

    TeachingTechnique.SOCRATIC: """\
ðŸ¦‰ SOCRATIC METHOD MODE:
You are a strict Socratic professor who NEVER gives direct answers.
Rules:
1. NEVER tell them the answer directly
2. Ask a leading question that forces them to discover the answer
3. When they answer correctly, praise them: "Excellent! Now consider..."
4. When they answer wrong, don't say "wrong" â€” instead ask a clarifying question
5. Break the problem into smaller sub-questions they can reason through
6. Your goal: make the student feel like THEY discovered the knowledge
7. Only reveal information after they've attempted to reason through it""",

    TeachingTechnique.ANALOGY_BRIDGE: """\
ðŸŒ‰ ANALOGY BRIDGE MODE:
You are connecting unknown concepts to things the student already understands.
Rules:
1. ALWAYS start by asking what the student is already familiar with
2. Build BRIDGES from their existing knowledge to new concepts
3. Every new concept gets at least TWO analogies from different domains
4. Use "It's like...", "Think of it as...", "Remember how X works? This is similar because..."
5. After the bridge, test it: "Where does the analogy break down?"
6. This forces deeper understanding than surface-level comparison
7. Use visual/spatial analogies when possible (maps, buildings, rivers)""",

    TeachingTechnique.CHUNKING: """\
ðŸ§© CHUNKING MODE:
You are breaking a massive topic into tiny, digestible micro-lessons.
Rules:
1. Split the entire topic into 5-7 numbered CHUNKS
2. Present ONLY ONE chunk at a time â€” don't overwhelm
3. Each chunk should take ~2 minutes to understand
4. Format: [Chunk Title] â†’ [Core Idea in 1 sentence] â†’ [Example] â†’ [Practice]
5. After each chunk: "Ready for the next piece of the puzzle?"
6. At the end, show how ALL chunks connect into the complete picture
7. Use progress indicators: "Chunk 3/6: [Title]" """,

    TeachingTechnique.ANTI_PATTERN: """\
ðŸš« ANTI-PATTERN MODE â€” "DON'T DO THIS" TEACHING:
You are teaching by showing what NOT to do, based on real system failures.
Rules:
1. Start EVERY lesson with a concrete BAD example â€” show the mistake first
2. Use âŒ and âœ… visual markers: "âŒ BAD: ..." vs "âœ… GOOD: ..."
3. Explain WHY the bad approach fails with specific technical reasons
4. Show the CORRECT approach as a direct contrast
5. State the universal principle/axiom that prevents this mistake
6. Ask: "Can you spot another scenario where this anti-pattern could appear?"
7. Use red/green metaphors: "This is a RED FLAG because..."
8. Include a recovery plan: "If you already made this mistake, here's how to fix it"
9. Rank dangers: "This is a CRITICAL / HIGH / MEDIUM severity anti-pattern""",

    TeachingTechnique.VISUAL_FLOWCHART: """\
ðŸ“Š VISUAL FLOWCHART MODE â€” TEACH WITH DIAGRAMS:
You are teaching by creating visual flowcharts and diagrams.
Rules:
1. For EVERY concept, provide a Mermaid flowchart diagram in ```mermaid blocks
2. Use decision flowcharts for "when to use A vs B" questions
3. Use process flowcharts for step-by-step procedures
4. Use concept maps to show how ideas relate to each other
5. Color-code: green for good paths, red for bad paths, blue for decisions
6. Keep diagrams focused â€” 6-12 nodes maximum
7. After each diagram, ask: "Does this diagram make the relationship clear?"
8. Provide ASCII art fallbacks for key visualizations
9. Use the diagram as the PRIMARY teaching tool, with text as support""",

    TeachingTechnique.GAME_CHALLENGE: """\
ðŸŽ® GAME CHALLENGE MODE â€” GAMIFIED LEARNING:
You are running a gamified challenge session with XP and achievements.
Rules:
1. Present questions as CHALLENGES with clear scoring
2. Award ðŸŒŸ XP for correct answers: Easy=10, Medium=20, Hard=50
3. Track streaks: "ðŸ”¥ STREAK: 3 correct in a row!"
4. Use difficulty tiers: ðŸŸ¢ Easy â†’ ðŸŸ¡ Medium â†’ ðŸ”´ Hard â†’ ðŸ’€ Expert
5. Give immediate feedback: "âœ… CORRECT! +20 XP" or "âŒ Not quite! The answer is..."
6. Provide progress bars: "Progress: â–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘â–‘â–‘â–‘â–‘ 40%"
7. Celebrate milestones: "ðŸ† ACHIEVEMENT UNLOCKED: Streak Warrior!"
8. At the end, show a SCOREBOARD with total XP, accuracy, and time
9. Make it FUN â€” use emojis, enthusiasm, and competitive language""",
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Difficulty Adaptation Prompts
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

_LEVEL_PROMPTS = {
    StudentLevel.BEGINNER: (
        "The student is a COMPLETE BEGINNER. "
        "Use everyday language. No jargon. Lots of analogies and examples. "
        "Assume ZERO prior knowledge. Be warm and encouraging."
    ),
    StudentLevel.INTERMEDIATE: (
        "The student has BASIC understanding and some experience. "
        "Use standard terminology but define advanced terms. "
        "Focus on WHY things work, not just HOW. Challenge them a little."
    ),
    StudentLevel.ADVANCED: (
        "The student is ADVANCED and understands core concepts well. "
        "Use technical language freely. Focus on edge cases, trade-offs, "
        "and real-world applications. Push them toward expert-level thinking."
    ),
    StudentLevel.EXPERT: (
        "The student is near-EXPERT level. "
        "Engage in peer-level discussion. Focus on cutting-edge research, "
        "open problems, and frontier knowledge. Cite specific papers/sources. "
        "Challenge their assumptions with contrarian viewpoints."
    ),
}


# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# Expert Tutor Engine
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

class ExpertTutorEngine:
    """
    Research-backed adaptive teaching engine.
    
    When the LLM doesn't know enough about a topic, it automatically
    triggers deep web + social media research and converts the results
    into expert-level coaching material that's easy to understand.
    """

    def __init__(self, generate_fn: Callable, agent_controller=None, memory_manager=None):
        """
        Args:
            generate_fn: The LLM generation function (prompt, system_prompt, temperature)
            agent_controller: Optional AgentController for deep research access
            memory_manager: Optional MemoryManager for mistake-based teaching
        """
        self.generate_fn = generate_fn
        self.agent = agent_controller
        self.memory_manager = memory_manager
        self._sessions: Dict[str, TutoringSession] = {}
        self._researcher = None
        self._mistake_engine = None
        self._flowchart_gen = None
        self._game_engine = None
        
        # Lazy-init researcher
        if agent_controller:
            try:
                from agents.profiles.deep_researcher import DeepWebResearcher
                self._researcher = DeepWebResearcher(agent_controller)
            except ImportError:
                logger.warning("DeepWebResearcher not available")

        # Init mistake lesson engine
        try:
            from brain.mistake_lesson_engine import MistakeLessonEngine
            self._mistake_engine = MistakeLessonEngine(
                memory_manager=memory_manager,
                generate_fn=generate_fn,
            )
        except ImportError:
            logger.warning("MistakeLessonEngine not available")

        # Init flowchart generator
        try:
            from brain.flowchart_generator import FlowchartGenerator
            self._flowchart_gen = FlowchartGenerator(generate_fn=generate_fn)
        except ImportError:
            logger.warning("FlowchartGenerator not available")

        # Init gamification engine
        try:
            from agents.profiles.gamified_tutor import GamifiedTutorEngine
            self._game_engine = GamifiedTutorEngine(generate_fn=generate_fn)
        except ImportError:
            logger.warning("GamifiedTutorEngine not available")

        logger.info("ðŸŽ“ ExpertTutorEngine initialized (with mistake/flowchart/game support)")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Session Management
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def start_session(self, topic: str, session_id: str = None) -> TutoringSession:
        """Start a new tutoring session on a topic."""
        import uuid
        session_id = session_id or uuid.uuid4().hex[:10]
        
        session = TutoringSession(
            session_id=session_id,
            topic=topic,
        )
        
        # Step 1: Generate initial LLM response to assess confidence
        probe_prompt = (
            f"Provide a comprehensive, expert-level explanation of: {topic}. "
            f"Cover the key concepts, principles, and latest developments. "
            f"Be specific and cite facts."
        )
        
        probe_result = self._call_llm(probe_prompt, "You are a knowledge assessment probe.")
        uncertainty_score, signals = detect_uncertainty(probe_result)
        
        logger.info(
            f"ðŸŽ“ Topic '{topic}' â€” LLM uncertainty: {uncertainty_score:.2f} "
            f"(signals: {len(signals)})"
        )
        
        # Step 2: If uncertain, trigger deep research
        if uncertainty_score > 0.3:
            logger.info(f"ðŸ”¬ Triggering deep research for topic: {topic}")
            session.research_intel = self._research_for_teaching(topic)
            session.research_triggered = True
        
        # Step 3: Build the lesson plan
        session.lesson_plan = self._build_lesson_plan(topic, session.research_intel)
        
        # Step 4: Choose initial teaching technique
        session.current_technique = self._select_technique(topic)
        
        # Step 5: Load anti-pattern lessons from the system's mistake history
        if self._mistake_engine:
            try:
                session.anti_pattern_lessons = self._mistake_engine.get_lessons_for_topic(topic)
                session.mistake_curriculum = self._mistake_engine.generate_curriculum(topic)
                if session.anti_pattern_lessons:
                    logger.info(
                        f"ðŸš« Loaded {len(session.anti_pattern_lessons)} anti-pattern lessons "
                        f"for topic '{topic}'"
                    )
            except Exception as e:
                logger.warning(f"Failed to load anti-pattern lessons: {e}")
        
        # Step 6: Initialize gamification player state
        if self._game_engine:
            session.player_state = self._game_engine.create_player()
            session.game_engine = self._game_engine
        
        self._sessions[session_id] = session
        
        logger.info(
            f"ðŸŽ“ Session {session_id}: topic='{topic}', "
            f"technique={session.current_technique.value}, "
            f"research={'YES' if session.research_triggered else 'NO'}, "
            f"lesson_steps={len(session.lesson_plan)}, "
            f"anti_patterns={len(session.anti_pattern_lessons)}, "
            f"gamified={'YES' if session.player_state else 'NO'}"
        )
        
        return session

    def get_session(self, session_id: str) -> Optional[TutoringSession]:
        return self._sessions.get(session_id)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Teaching Flow
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def begin_teaching(self, session: TutoringSession) -> str:
        """Generate the opening diagnostic + first teaching message."""
        system_prompt = self._build_system_prompt(session)
        
        # Build opening that includes a diagnostic question
        opening_prompt = (
            f"You are starting a tutoring session on: {session.topic}\n\n"
            f"LESSON PLAN:\n"
        )
        for i, step in enumerate(session.lesson_plan):
            opening_prompt += f"  {i+1}. {step}\n"
        
        opening_prompt += (
            "\nFirst, give a brief exciting introduction about WHY this topic matters "
            "(2-3 sentences). Then ask ONE diagnostic question to assess the student's "
            "current level. The question should have 3 difficulty levels embedded "
            "(easy/medium/hard) so you can gauge where they are."
        )
        
        # Include research intelligence if available
        if session.research_intel:
            opening_prompt += self._format_research_context(session.research_intel)
        
        response = self._call_llm(opening_prompt, system_prompt, temperature=0.7)
        
        session.history.append({"role": "assistant", "content": response})
        return response

    def respond_to_student(
        self, session: TutoringSession, student_message: str
    ) -> str:
        """
        Process student's response and generate next coaching step.
        
        This is the core teaching loop:
          1. Analyze student response for understanding level
          2. Update difficulty
          3. Check if we need more research
          4. Generate next coaching step using active technique
        """
        session.history.append({"role": "user", "content": student_message})
        
        # Diagnose student level from their response
        diagnosis = self._diagnose_student(session, student_message)
        session.diagnostic = diagnosis
        session.student_level = diagnosis.level
        
        # Check if student asked about something we might not know enough about
        follow_up_uncertainty = self._check_followup_knowledge(
            session, student_message
        )
        
        if follow_up_uncertainty > 0.4 and not session.research_triggered:
            logger.info(f"ðŸ”¬ Student question triggered deep research: {student_message[:60]}")
            session.research_intel = self._research_for_teaching(
                f"{session.topic}: {student_message}"
            )
            session.research_triggered = True
        
        # Build next coaching response
        system_prompt = self._build_system_prompt(session)
        
        # Build conversational context (last 10 exchanges max)
        context_messages = session.history[-20:]
        chat_context = ""
        for msg in context_messages:
            role = "STUDENT" if msg["role"] == "user" else "COACH"
            chat_context += f"{role}: {msg['content']}\n\n"
        
        # Progress tracking
        progress = ""
        if session.lesson_plan:
            step_idx = min(session.current_lesson_step, len(session.lesson_plan) - 1)
            progress = (
                f"\n\nCURRENT PROGRESS: Step {step_idx + 1}/{len(session.lesson_plan)}: "
                f"{session.lesson_plan[step_idx]}"
            )
        
        teaching_prompt = (
            f"Dialogue so far:\n{chat_context}\n"
            f"STUDENT DIAGNOSIS: Level={diagnosis.level.value}, "
            f"Gaps={diagnosis.knowledge_gaps}, Strengths={diagnosis.strengths}\n"
            f"{progress}\n\n"
            f"The student just said: \"{student_message}\"\n\n"
            f"Generate your next coaching response. Remember to use the "
            f"{session.current_technique.value} technique. "
            f"If the student shows they understand the current concept, "
            f"advance to the next lesson step."
        )
        
        # Include research if available
        if session.research_intel:
            teaching_prompt += self._format_research_context(session.research_intel)
        
        # Include anti-pattern lessons if in ANTI_PATTERN mode or if relevant
        if session.anti_pattern_lessons:
            if (session.current_technique == TeachingTechnique.ANTI_PATTERN
                or session.anti_patterns_shown < len(session.anti_pattern_lessons)):
                teaching_prompt += self._format_anti_pattern_context(session)
        
        # Include flowchart if in VISUAL_FLOWCHART mode
        if (session.current_technique == TeachingTechnique.VISUAL_FLOWCHART
            and self._flowchart_gen):
            teaching_prompt += self._format_flowchart_context(session, student_message)
        
        response = self._call_llm(teaching_prompt, system_prompt, temperature=0.7)
        
        # Track confidence and advance lesson
        session.history.append({"role": "assistant", "content": response})
        
        # Auto-advance lesson if student shows understanding
        if diagnosis.confidence > 0.7 and session.lesson_plan:
            if session.current_lesson_step < len(session.lesson_plan) - 1:
                session.current_lesson_step += 1
        
        return response

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Interactive CLI Session
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def start_interactive(self, topic: str):
        """Start an interactive tutoring session in the console."""
        print(f"\n{'='*60}")
        print("  ðŸŽ“ EXPERT TUTOR ENGINE â€” Interactive Session")
        print(f"  Topic: {topic}")
        print(f"{'='*60}")
        
        session = self.start_session(topic)
        
        if session.research_triggered:
            print("\nðŸ”¬ Deep Research triggered â€” I'll be using expert sources from")
            print("   the web, academic papers, and social media to teach you.\n")
        
        print(f"ðŸ“š Teaching technique: {session.current_technique.value}")
        print(f"ðŸ“‹ Lesson plan: {len(session.lesson_plan)} steps")
        print("\nType 'exit', 'quit', or 'done' to end the session.")
        print("Type 'switch <technique>' to change teaching style.")
        print("  Techniques: feynman, scaffolding, socratic, analogy_bridge, chunking")
        print(f"{'â”€'*60}\n")
        
        # Opening message
        opening = self.begin_teaching(session)
        print(f"ðŸŽ“ Coach: {opening}\n")
        
        while True:
            try:
                user_input = input("You: ").strip()
                
                if not user_input:
                    continue
                
                if user_input.lower() in ('exit', 'quit', 'done'):
                    self._end_session_summary(session)
                    break
                
                # Handle technique switching
                if user_input.lower().startswith('switch '):
                    technique_name = user_input[7:].strip().lower()
                    try:
                        session.current_technique = TeachingTechnique(technique_name)
                        print(f"\nðŸ“š Switched to {technique_name} technique!\n")
                        continue
                    except ValueError:
                        print(f"\nâŒ Unknown technique: {technique_name}")
                        print("   Available: feynman, scaffolding, socratic, analogy_bridge, chunking\n")
                        continue
                
                # Generate coaching response
                response = self.respond_to_student(session, user_input)
                
                # Show progress
                step = min(session.current_lesson_step + 1, len(session.lesson_plan))
                total = len(session.lesson_plan) or 1
                level = session.student_level.value
                print(f"\n[ðŸ“Š Level: {level} | Step: {step}/{total}]")
                print(f"ðŸŽ“ Coach: {response}\n")
                
            except KeyboardInterrupt:
                self._end_session_summary(session)
                break
            except Exception as e:
                logger.error(f"Tutor error: {e}", exc_info=True)
                print("\nâš ï¸ Teaching error occurred. Let me try again.\n")

    def _end_session_summary(self, session: TutoringSession):
        """Print a session summary when the student exits."""
        elapsed = time.time() - session.started_at
        minutes = int(elapsed / 60)
        exchanges = len([m for m in session.history if m["role"] == "user"])
        
        print(f"\n{'='*60}")
        print("  ðŸ“Š SESSION SUMMARY")
        print(f"{'='*60}")
        print(f"  Topic: {session.topic}")
        print(f"  Duration: {minutes} minutes")
        print(f"  Exchanges: {exchanges}")
        print(f"  Final Level: {session.student_level.value}")
        print(f"  Research Used: {'Yes' if session.research_triggered else 'No'}")
        print(f"  Technique: {session.current_technique.value}")
        if session.lesson_plan:
            step = min(session.current_lesson_step + 1, len(session.lesson_plan))
            print(f"  Progress: {step}/{len(session.lesson_plan)} steps completed")
        print("\n  ðŸŽ“ Great work today! Keep learning! ðŸš€")
        print(f"{'='*60}\n")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Deep Research for Teaching
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _research_for_teaching(self, topic: str) -> ResearchIntel:
        """
        Trigger deep research and convert raw intelligence into
        structured teaching material.
        """
        intel = ResearchIntel(topic=topic)
        
        try:
            from agents.tools.web_search import advanced_web_search
            
            # 1. Surface web â€” practical explanations
            surface = advanced_web_search(
                f"explain {topic} simply with examples",
                network="surface", max_results=5, deep_scrape=True,
            )
            for item in surface.get("results", []):
                content = item.get("full_content") or item.get("snippet", "")
                if content and len(content) > 50:
                    intel.real_world_examples.append(content[:800])
                    intel.sources.append({
                        "title": item.get("title", ""),
                        "url": item.get("href", ""),
                        "type": "surface",
                    })
            
            # 2. Social media â€” Reddit ELI5 + expert discussions
            social = advanced_web_search(
                f"{topic} ELI5 explained simple",
                network="social", max_results=5,
            )
            for item in social.get("results", []):
                snippet = item.get("snippet", "")
                if snippet and len(snippet) > 30:
                    intel.social_wisdom.append(snippet[:600])
                    intel.eli5_explanations.append(snippet[:400])
                    intel.sources.append({
                        "title": item.get("title", ""),
                        "url": item.get("href", ""),
                        "type": "social",
                    })
            
            # 3. Academic â€” deep/ArXiv for expert-level insights
            academic = advanced_web_search(
                topic, network="deep", max_results=5,
            )
            for item in academic.get("results", []):
                snippet = item.get("snippet", "")
                if snippet:
                    intel.academic_findings.append(snippet[:800])
                    intel.expert_insights.append(
                        f"[{item.get('title', 'Research')}]: {snippet[:300]}"
                    )
                    intel.sources.append({
                        "title": item.get("title", ""),
                        "url": item.get("href", ""),
                        "type": "academic",
                    })
            
            logger.info(
                f"ðŸ”¬ Research compiled: {len(intel.real_world_examples)} examples, "
                f"{len(intel.eli5_explanations)} ELI5s, "
                f"{len(intel.academic_findings)} academic, "
                f"{len(intel.social_wisdom)} social"
            )
            
        except Exception as e:
            logger.error(f"Research failed: {e}", exc_info=True)
        
        # Generate practice problems using LLM
        if intel.real_world_examples or intel.academic_findings:
            try:
                problem_prompt = (
                    f"Based on this topic: {topic}\n"
                    f"Generate 3 practice problems/exercises for a student, "
                    f"ordered from easy to hard. Format as numbered list. "
                    f"Each problem should have a brief hint."
                )
                problems = self._call_llm(problem_prompt, "You are an expert educator.")
                intel.practice_problems = [problems]
            except Exception:
                pass
        
        return intel

    def _format_research_context(self, intel: ResearchIntel) -> str:
        """Format research intelligence for injection into the teaching prompt."""
        parts = ["\n\n--- DEEP RESEARCH INTELLIGENCE (use to enrich your teaching) ---"]
        
        if intel.eli5_explanations:
            parts.append("\nðŸ“± COMMUNITY EXPLANATIONS (Reddit/Social):")
            for i, exp in enumerate(intel.eli5_explanations[:3]):
                parts.append(f"  {i+1}. {exp[:300]}")
        
        if intel.expert_insights:
            parts.append("\nðŸ”¬ ACADEMIC/EXPERT INSIGHTS:")
            for i, insight in enumerate(intel.expert_insights[:3]):
                parts.append(f"  {i+1}. {insight[:300]}")
        
        if intel.real_world_examples:
            parts.append("\nðŸŒ REAL-WORLD EXAMPLES:")
            for i, ex in enumerate(intel.real_world_examples[:2]):
                parts.append(f"  {i+1}. {ex[:300]}")
        
        if intel.practice_problems:
            parts.append("\nâœï¸ PRACTICE PROBLEMS (offer these to the student):")
            for prob in intel.practice_problems[:1]:
                parts.append(f"  {prob[:500]}")
        
        parts.append("\n--- END RESEARCH INTELLIGENCE ---")
        parts.append(
            "\nIMPORTANT: Weave this intelligence naturally into your teaching. "
            "Don't dump it all at once. Use it to give specific, real examples "
            "and cite expert sources when it makes the explanation richer."
        )
        
        return "\n".join(parts)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Student Diagnosis
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _diagnose_student(
        self, session: TutoringSession, student_msg: str
    ) -> DiagnosticResult:
        """Analyze the student's response to determine their level."""
        result = DiagnosticResult()
        msg_lower = student_msg.lower()
        word_count = len(student_msg.split())
        
        # Indicators of different levels
        beginner_signals = [
            "i don't know", "what is", "what's", "i have no idea",
            "never heard", "confused", "don't understand", "huh",
            "idk", "no clue", "explain",
        ]
        
        intermediate_signals = [
            "i think", "maybe because", "is it like", "i remember",
            "so basically", "i've heard", "i know a little",
        ]
        
        advanced_signals = [
            "because", "therefore", "the reason is", "this implies",
            "trade-off", "alternatively", "however", "specifically",
            "in my experience", "the key insight",
        ]
        
        expert_signals = [
            "according to", "the paper by", "the algorithm",
            "complexity is", "formally", "proof", "theorem",
            "implementation detail", "the specification",
        ]
        
        # Score each level
        scores = {
            StudentLevel.BEGINNER: sum(1 for s in beginner_signals if s in msg_lower),
            StudentLevel.INTERMEDIATE: sum(1 for s in intermediate_signals if s in msg_lower),
            StudentLevel.ADVANCED: sum(1 for s in advanced_signals if s in msg_lower),
            StudentLevel.EXPERT: sum(1 for s in expert_signals if s in msg_lower),
        }
        
        # Longer, more detailed responses indicate higher level
        if word_count > 50:
            scores[StudentLevel.ADVANCED] += 1
        if word_count > 100:
            scores[StudentLevel.EXPERT] += 1
        if word_count < 10:
            scores[StudentLevel.BEGINNER] += 1
        
        # Pick highest
        best_level = max(scores, key=scores.get)
        best_score = scores[best_level]
        
        if best_score == 0:
            # No signals â€” keep current level
            result.level = session.student_level
            result.confidence = 0.5
        else:
            result.level = best_level
            result.confidence = min(1.0, best_score * 0.25)
        
        # Detect knowledge gaps (questions the student asks)
        if "?" in student_msg:
            questions = [q.strip() + "?" for q in student_msg.split("?") if q.strip()]
            result.knowledge_gaps = questions[:3]
        
        # Detect strengths (correct terms they use)
        tech_terms = re.findall(r'\b[A-Z][a-z]+(?:[A-Z][a-z]+)+\b', student_msg)  # CamelCase
        if tech_terms:
            result.strengths = tech_terms[:3]
        
        return result

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Helpers
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _call_llm(
        self, prompt: str, system_prompt: str = "", temperature: float = 0.7
    ) -> str:
        """Call the LLM generation function safely."""
        try:
            result = self.generate_fn(
                prompt=prompt,
                system_prompt=system_prompt,
                temperature=temperature,
            )
            if hasattr(result, 'answer'):
                return result.answer
            if hasattr(result, 'error') and result.error:
                return f"[LLM Error: {result.error}]"
            return str(result)
        except Exception as e:
            logger.error(f"LLM call failed: {e}")
            return "[Unable to generate response â€” using cached knowledge]"

    def _build_system_prompt(self, session: TutoringSession) -> str:
        """Build the full system prompt combining technique + level + research."""
        parts = [
            "You are an ELITE expert tutor with decades of teaching experience.",
            "You adapt your teaching to the student's exact level and learning style.",
            "",
            _TECHNIQUE_PROMPTS.get(session.current_technique, ""),
            "",
            _LEVEL_PROMPTS.get(session.student_level, ""),
        ]
        
        if session.lesson_plan:
            parts.append(f"\nLESSON PLAN: {json.dumps(session.lesson_plan)}")
        
        return "\n".join(parts)

    def _build_lesson_plan(
        self, topic: str, research: Optional[ResearchIntel] = None
    ) -> List[str]:
        """Generate a structured lesson plan for the topic."""
        context = ""
        if research and research.expert_insights:
            context = (
                "\nUse these expert insights to inform the plan:\n"
                + "\n".join(research.expert_insights[:3])
            )
        
        prompt = (
            f"Create a lesson plan for teaching: {topic}\n"
            f"Generate exactly 5-7 steps, ordered from foundation to mastery.\n"
            f"Each step should be a short phrase (5-10 words max).\n"
            f"Format: one step per line, no numbers or bullets.\n"
            f"{context}"
        )
        
        result = self._call_llm(prompt, "You are a curriculum designer.", temperature=0.5)
        
        # Parse into list
        lines = [line.strip().lstrip("0123456789.-) ") for line in result.split("\n")]
        plan = [line for line in lines if line and len(line) > 5 and len(line) < 100]
        
        if not plan:
            # Fallback generic plan
            plan = [
                f"What is {topic} and why it matters",
                "Core concepts and terminology",
                f"How {topic} works step by step",
                "Real-world applications and examples",
                "Common mistakes and misconceptions",
                "Practice problems and exercises",
                "Advanced topics and next steps",
            ]
        
        return plan[:7]

    def _select_technique(self, topic: str) -> TeachingTechnique:
        """Select the best teaching technique for a topic."""
        topic_lower = topic.lower()
        
        # Math/science â†’ scaffolding (build layer by layer)
        if any(w in topic_lower for w in [
            "math", "calculus", "algebra", "physics", "chemistry",
            "algorithm", "data structure", "proof", "theorem",
        ]):
            return TeachingTechnique.SCAFFOLDING
        
        # Abstract concepts â†’ analogy bridge
        if any(w in topic_lower for w in [
            "quantum", "philosophy", "theory", "abstract",
            "consciousness", "relativity", "economics",
        ]):
            return TeachingTechnique.ANALOGY_BRIDGE
        
        # Practical skills â†’ Feynman
        if any(w in topic_lower for w in [
            "programming", "code", "python", "javascript", "web",
            "cooking", "fitness", "design", "build", "create",
        ]):
            return TeachingTechnique.FEYNMAN
        
        # Large topics â†’ chunking
        if any(w in topic_lower for w in [
            "history", "overview", "complete guide", "everything about",
            "introduction to", "full course",
        ]):
            return TeachingTechnique.CHUNKING
        
        # Default â†’ scaffolding (most universally effective)
        return TeachingTechnique.SCAFFOLDING

    def _check_followup_knowledge(
        self, session: TutoringSession, student_msg: str
    ) -> float:
        """Check if a student's follow-up question requires more research."""
        # If student asks about something very specific we might not know
        specific_indicators = [
            "latest", "newest", "recent", "2024", "2025", "2026",
            "current", "today", "right now", "updated",
            "specific paper", "who invented", "exact number",
        ]
        
        msg_lower = student_msg.lower()
        specificity_score = sum(
            0.15 for indicator in specific_indicators 
            if indicator in msg_lower
        )
        
        return min(1.0, specificity_score)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Anti-Pattern & Flowchart Context
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def _format_anti_pattern_context(self, session: TutoringSession) -> str:
        """Format anti-pattern lessons as context for the teaching prompt."""
        if not session.anti_pattern_lessons:
            return ""

        parts = ["\n\n--- ANTI-PATTERN LESSONS (teach these as 'Don't Do This' warnings) ---"]

        # Show the next unshown anti-pattern lesson
        idx = session.anti_patterns_shown
        if idx < len(session.anti_pattern_lessons) and self._mistake_engine:
            lesson = session.anti_pattern_lessons[idx]
            parts.append(self._mistake_engine.format_lesson_for_prompt(lesson))
            session.anti_patterns_shown += 1

            # Award gamification XP
            if session.player_state and session.game_engine:
                session.game_engine.record_anti_pattern_learned(session.player_state)

        parts.append("--- END ANTI-PATTERN LESSONS ---")
        parts.append(
            "IMPORTANT: Weave these anti-patterns naturally into your teaching. "
            "Show the bad approach first with âŒ, then contrast with the good approach âœ…. "
            "Explain WHY the mistake is dangerous."
        )
        return "\n".join(parts)

    def _format_flowchart_context(self, session: TutoringSession, student_msg: str) -> str:
        """Generate and format a flowchart for the current teaching context."""
        if not self._flowchart_gen:
            return ""

        try:
            from brain.flowchart_generator import FlowchartType

            # Select appropriate flowchart type based on context
            msg_lower = student_msg.lower()
            if any(w in msg_lower for w in ["choose", "decision", "which", "should i", "vs"]):
                chart_type = FlowchartType.DECISION
            elif any(w in msg_lower for w in ["how", "steps", "process", "procedure"]):
                chart_type = FlowchartType.PROCESS
            elif any(w in msg_lower for w in ["wrong", "mistake", "bad", "don't", "avoid"]):
                chart_type = FlowchartType.ANTI_PATTERN
            elif any(w in msg_lower for w in ["relate", "connect", "map", "overview"]):
                chart_type = FlowchartType.CONCEPT_MAP
            elif any(w in msg_lower for w in ["compare", "difference", "versus", "pros cons"]):
                chart_type = FlowchartType.COMPARISON
            elif any(w in msg_lower for w in ["debug", "fix", "error", "bug"]):
                chart_type = FlowchartType.DEBUG_TRACE
            else:
                chart_type = FlowchartType.PROCESS

            chart = self._flowchart_gen.generate(
                topic=session.topic,
                chart_type=chart_type,
                context=student_msg,
            )

            # Award flowchart XP
            if session.player_state and session.game_engine:
                session.game_engine.record_flowchart_requested(session.player_state)

            return (
                "\n\n--- VISUAL FLOWCHART (include in your response as a mermaid block) ---\n"
                f"```mermaid\n{chart}\n```\n"
                "--- END FLOWCHART ---\n"
                "IMPORTANT: Include this flowchart in your response inside a ```mermaid block. "
                "Explain each node in the diagram. Ask the student to trace through it."
            )
        except Exception as e:
            logger.warning(f"Flowchart generation failed: {e}")
            return ""

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Gamification API Methods
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def get_game_dashboard(self, session_id: str) -> Optional[str]:
        """Get the gamification dashboard for a session."""
        session = self.get_session(session_id)
        if not session or not session.player_state or not session.game_engine:
            return None
        from agents.profiles.gamified_tutor import render_dashboard
        return render_dashboard(session.player_state)

    def start_challenge(self, session_id: str, mode: str = "quiz") -> Optional[Dict[str, Any]]:
        """Start a gamified challenge within a tutoring session."""
        session = self.get_session(session_id)
        if not session or not session.game_engine:
            return None

        from agents.profiles.gamified_tutor import ChallengeMode
        try:
            challenge_mode = ChallengeMode(mode)
        except ValueError:
            challenge_mode = ChallengeMode.QUIZ

        challenge = session.game_engine.create_challenge(
            mode=challenge_mode,
            topic=session.topic,
        )
        session.active_challenge = challenge

        return {
            "challenge_id": challenge.id,
            "mode": challenge.mode.value,
            "questions": len(challenge.questions),
            "first_question": challenge.questions[0].question if challenge.questions else "",
            "options": challenge.questions[0].options if challenge.questions else [],
        }

    def answer_challenge(self, session_id: str, answer: str) -> Optional[Dict[str, Any]]:
        """Answer the current challenge question."""
        session = self.get_session(session_id)
        if not session or not session.active_challenge or not session.game_engine:
            return None

        return session.game_engine.answer_challenge(
            challenge_id=session.active_challenge.id,
            answer=answer,
            state=session.player_state,
        )

    def generate_flowchart(self, session_id: str, chart_type: str = "process") -> Optional[str]:
        """Generate a standalone flowchart for a session's topic."""
        session = self.get_session(session_id)
        if not session or not self._flowchart_gen:
            return None

        from brain.flowchart_generator import FlowchartType
        try:
            ftype = FlowchartType(chart_type)
        except ValueError:
            ftype = FlowchartType.PROCESS

        return self._flowchart_gen.generate(topic=session.topic, chart_type=ftype)

    def get_anti_patterns(self, session_id: str) -> List[Dict[str, Any]]:
        """Get all anti-pattern lessons for a session."""
        session = self.get_session(session_id)
        if not session or not session.anti_pattern_lessons:
            return []

        return [
            {
                "title": l.title,
                "category": l.category,
                "danger_score": l.danger_score,
                "bad_approach": l.bad_approach,
                "correct_approach": l.correct_approach,
                "expert_principle": l.expert_principle,
                "flowchart": l.flowchart,
            }
            for l in session.anti_pattern_lessons
        ]

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # API-Compatible Methods
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    def api_start_session(self, topic: str) -> Dict[str, Any]:
        """API endpoint compatible: start a session and return opening message."""
        session = self.start_session(topic)
        opening = self.begin_teaching(session)
        
        return {
            "session_id": session.session_id,
            "topic": session.topic,
            "technique": session.current_technique.value,
            "research_used": session.research_triggered,
            "lesson_plan": session.lesson_plan,
            "opening_message": opening,
            "anti_patterns_loaded": len(session.anti_pattern_lessons),
            "gamification_active": session.player_state is not None,
        }

    def api_respond(self, session_id: str, message: str) -> Dict[str, Any]:
        """API endpoint compatible: process student response."""
        session = self.get_session(session_id)
        if not session:
            return {"error": f"Session not found: {session_id}"}
        
        response = self.respond_to_student(session, message)
        
        result = {
            "session_id": session_id,
            "response": response,
            "student_level": session.student_level.value,
            "technique": session.current_technique.value,
            "lesson_progress": {
                "current_step": session.current_lesson_step + 1,
                "total_steps": len(session.lesson_plan),
                "current_topic": (
                    session.lesson_plan[session.current_lesson_step]
                    if session.lesson_plan else ""
                ),
            },
            "research_used": session.research_triggered,
            "anti_patterns_shown": session.anti_patterns_shown,
        }
        
        # Include gamification data if active
        if session.player_state:
            result["gamification"] = {
                "xp": session.player_state.xp,
                "level": session.player_state.level.value,
                "streak": session.player_state.streak,
                "achievements_unlocked": sum(
                    1 for a in session.player_state.achievements.values()
                    if a.unlocked
                ),
            }
        
        return result
